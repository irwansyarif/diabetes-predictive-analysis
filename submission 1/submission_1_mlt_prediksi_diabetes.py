# -*- coding: utf-8 -*-
"""Submission 1 MLT Prediksi Diabetes

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mJB0ai5eSSo2YC9lGx8pDarjGJVy-hVd

# Import Library
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.io as pio
from sklearn.preprocessing import LabelEncoder,StandardScaler
from sklearn.metrics import accuracy_score,confusion_matrix,f1_score
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
import warnings
warnings.simplefilter('ignore')

"""# Download Dataset"""

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d iammustafatz/diabetes-prediction-dataset

import zipfile
zip_ref = zipfile.ZipFile('/content/diabetes-prediction-dataset.zip', 'r')
zip_ref.extractall('/content')
zip_ref.close()

"""# DATA PREPROCESSING

#### Data Processing merupakan proses memahami informasi dalam data dan menentukan kualitas dari data tersebut.
"""

df = pd.read_csv('/content/diabetes_prediction_dataset.csv')

df.info()

"""### Pengecekan data yang terdindikasi duplikat"""

df.duplicated().sum()

df.drop_duplicates(inplace=True)
df.duplicated().sum()
df['smoking_history'].value_counts() # 35816 no info so we should drop columns to avoid inaccureate data

"""#### Melakukan Drop Column pada kolom smoking_history"""

df.drop(columns=['smoking_history'],inplace=True) #preprocessing

df

df.info()

"""# EDA

Exploratory data analysis merupakan proses investigasi awal pada data untuk menganalisis karakteristik, menemukan pola, anomali, dan memeriksa asumsi pada data. Teknik ini biasanya menggunakan bantuan statistik dan representasi grafis atau visualisasi.
"""

cat_features = ['gender']
num_features = ['age','hypertension','heart_disease','bmi','HbA1c_level','blood_glucose_level','diabetes']

feature = cat_features[0]
count = df[feature].value_counts()
percent = 100*df[feature].value_counts(normalize=True)
df2 = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df2)
count.plot(kind='bar', title=feature);

df.hist(bins=50, figsize=(20,15))
plt.show()

"""# MULTIVARIATE ANALYSIS"""

sns.pairplot(df, diag_kind = 'kde')

sns.heatmap(df.corr(numeric_only=True),annot=True)
plt.show()

"""# BIVARIATE ANALYSIS"""

sns.boxplot(x ='diabetes', y='bmi', data=df)
plt.show()

sns.boxplot(x='diabetes', y='age', data=df)
plt.show()

sns.countplot(x = 'gender', hue  = 'diabetes', data=df)
plt.show()

sns.boxplot(x ='diabetes', y= 'HbA1c_level', data=df)
plt.show()

sns.boxplot(x = 'diabetes', y= 'blood_glucose_level', data =df)
plt.show()

sns.scatterplot(x='age', y='bmi', hue ='diabetes', data=df)
plt.show()

sns.violinplot(x= 'diabetes', y='bmi', hue="gender",  data=df)
plt.show()

sns.boxplot(x='diabetes', y='bmi', hue='gender', data=df)
plt.show()

sns.boxplot(x= 'diabetes', y='bmi', hue='gender', data=df)
plt.show()

sns.boxplot(x='diabetes', y='age', hue='gender', data=df)
plt.show()

"""#### dilakukan proses pengubahan data kategorikal pada kolom gender menjadi nilai numerik"""

encoder = LabelEncoder()
df['gender'] = encoder.fit_transform(df['gender'])

"""#### Proses untuk mendeteksi dan menghapus outlier (data pencilan) dari fitur numerik."""

numeric_columns = df.select_dtypes(include=['number']).columns  # Semua angka
Q1 = df[numeric_columns].quantile(0.25)
Q3 = df[numeric_columns].quantile(0.75)
IQR = Q3 - Q1
df_clean = df[~((df[numeric_columns] < (Q1 - 1.5 * IQR)) | (df[numeric_columns] > (Q3 + 1.5 * IQR))).any(axis=1)]

"""## Split dataset

#### Pembagian dataset menjadi 80% digunakan untuk training model dan 20% untuk mengevaluasi model.
"""

from sklearn.model_selection import train_test_split
# Menentukan fitur (X) dan label (y)
X = df.drop(["diabetes"],axis =1)
y = df["diabetes"]

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Print dataset sizes
print("Training set size:", X_train.shape)
print("Testing set size:", X_test.shape)

"""## Normalisasi

#### MinMaxScaler adalah teknik normalisasi yang mengubah nilai fitur atau variabel ke dalam rentang [0,1] yang berarti bahwa nilai minimum dan maksimum dari fitur/variabel masing-masing adalah 0 dan 1
"""

from sklearn.preprocessing import MinMaxScaler

# Normalisasi dengan MinMaxScaler
scaler = MinMaxScaler()
scaler.fit(X_train)
X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)

"""# Make Models

Membuat beberapa model yang untuk mencari model mana yang lebih akurat diantara yang lainnya.
"""

# Menyiapkan dataframe untuk analisis model
models = pd.DataFrame(index=['accuracy_score'],
                      columns=['KNN', 'RandomForest', 'SVM', 'Decision Tree','Naive Bayes'])

"""# KNN"""

from sklearn.neighbors import KNeighborsClassifier

# Buat model prediksi dengan KNN
model_knn = KNeighborsClassifier(n_neighbors=3)
model_knn.fit(X_train, y_train)

# Lakukan prediksi dengan model KNN
knn_pred = model_knn.predict(X_test)

# Hitung metriks akurasi dan simpan hasilnya
models.loc['accuracy_score','KNN'] = accuracy_score(y_test, knn_pred)

"""# Random Forest"""

from sklearn.ensemble import RandomForestClassifier

# Train a model
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

from sklearn.metrics import confusion_matrix, classification_report

import matplotlib.pyplot as plt


# Lakukan prediksi dengan model Random Forest
rf_pred = rf_model.predict(X_test)

# Hitung metriks akurasi dan simpan hasilnya
models.loc['accuracy_score','RandomForest'] = accuracy_score(y_test, rf_pred)

import seaborn as sns

# Create and visualize confusion matrix
cm = confusion_matrix(y_test, rf_pred)

# Plot confusion matrix using seaborn
plt.figure(figsize=(6,4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Negative', 'Positive', 'Neutral'], yticklabels=['Negative', 'Positive', 'Neutral'])
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

"""# SVM"""

from sklearn.svm import SVC

# Train an SVM model
svm_model = SVC(kernel='linear', random_state=42, C=7.5)
svm_model.fit(X_train, y_train)

# Lakukan prediksi dengan model SVM Classifier
svm_pred = svm_model.predict(X_test)

# Hitung metriks akurasi dan simpan hasilnya
models.loc['accuracy_score','SVM'] = accuracy_score(y_test, svm_pred)

"""# Decision Tree"""

from sklearn.tree import DecisionTreeClassifier

# Train a Decision Tree model
dt_model = DecisionTreeClassifier(random_state=42)
dt_model.fit(X_train, y_train)

# Lakukan prediksi dengan model Decision Tree Model
dt_pred = dt_model.predict(X_test)

# Hitung metriks akurasi dan simpan hasilnya
models.loc['accuracy_score','Decision Tree'] = accuracy_score(y_test, dt_pred)

"""# Naive Bayes"""

from sklearn.naive_bayes import BernoulliNB

# Buat model prediksi dengan Bernoulli Naive Bayes
model_nb = BernoulliNB()
model_nb.fit(X_train, y_train)

# Lakukan prediksi dengan model Naive Bayes
nb_pred = model_nb.predict(X_test)

# Hitung metriks akurasi dan simpan hasilnya
models.loc['accuracy_score','Naive Bayes'] = accuracy_score(y_test, nb_pred)

"""# Evaluasi model

Proses Evaluasi Model merupakan tahap untuk membuktikan suatu model cocok dengan tujuan yang telah ditentukan dan untuk memastikan model mampu membuat prediksi yang akurat.
"""

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

y_pred_knn = model_knn.predict(X_test)
y_pred_svm = svm_model.predict(X_test)
y_pred_rf = rf_model.predict(X_test)
y_pred_dt = dt_model.predict(X_test)
y_pred_nb = model_nb.predict(X_test)

accuracy_scores = {}

# Calculate evaluation metrics for each model
def evaluate_model(y_true, y_pred, model_name):
    accuracy = accuracy_score(y_true, y_pred)
    precision = precision_score(y_true, y_pred)
    recall = recall_score(y_true, y_pred)
    f1 = f1_score(y_true, y_pred)
    print(f"Metrics for {model_name}:")
    print(f"  Accuracy: {accuracy:.4f}")
    print(f"  Precision: {precision:.4f}")
    print(f"  Recall: {recall:.4f}")
    print(f"  F1-score: {f1:.4f}")
    print("-" * 20)

evaluate_model(y_test, y_pred_knn, "KNN")
evaluate_model(y_test, y_pred_svm, "SVM")
evaluate_model(y_test, y_pred_rf, "Random Forest")
evaluate_model(y_test, y_pred_dt, "Decision Tree")
evaluate_model(y_test, y_pred_nb, "Naive Bayes")

"""Kesimpulan Evaluasi Dari setiap model

- Model Random Forest memberikan hasil terbaik dengan kombinasi accuracy, precision, recall, dan F1-score yang paling seimbang dan tinggi.

- KNN memiliki accuracy yang tinggi, namun recall relatif rendah, yang berarti masih banyak kasus positif yang gagal terdeteksi.

- SVM menghasilkan precision tinggi, namun recall cukup rendah, artinya model sangat berhati-hati (minim false positive), tapi kurang menangkap banyak kasus positif.

- Naive Bayes memiliki performa yang jauh lebih rendah dibandingkan model lainnya.

## Membuat grafik perbandingan dari kelima model yang telah dibuat
"""

import matplotlib.pyplot as plt
import numpy as np

# Skor akurasi dan nama model
model_names = ['KNN', 'SVM', 'Random Forest', 'Decision Tree', 'Naive Bayes']
accuracy_scores = [
    accuracy_score(y_test, y_pred_knn),
    accuracy_score(y_test, y_pred_svm),
    accuracy_score(y_test, y_pred_rf),
    accuracy_score(y_test, y_pred_dt),
    accuracy_score(y_test, y_pred_nb)
]

# Warna berbeda untuk setiap model
colors = ['Blue', 'Orange', 'Green', 'Red', 'Purple']  # Blue, Orange, Green, Red, Purple
x = np.arange(len(model_names))

plt.figure(figsize=(10, 6))
bars = plt.bar(x, accuracy_scores, color=colors)

# Menambahkan nilai akurasi di atas bar
for bar, score in zip(bars, accuracy_scores):
    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.01,
             f'{score:.4f}', ha='center', va='bottom', fontsize=10, fontweight='bold')

# Konfigurasi tampilan
plt.xticks(x, model_names)
plt.ylim(0, 1.05)
plt.ylabel('Accuracy')
plt.title('Accuracy Score per Model')
plt.legend(bars, model_names, loc='upper center', bbox_to_anchor=(0.5, 1.1), ncol=3)
plt.grid(axis='y', linestyle='--', alpha=0.6)

plt.tight_layout()
plt.show()

"""##### Dari diagram diatas dapat kita lihat bahwa model Random Forest adalah Model tertinggi daripada keempat model lainnya. Dengan itu, maka model ini yang akan dipakai. Model ini memberikan dampak nyata dalam meningkatkan efisiensi dan ketepatan dalam proses penilaian risiko diabetes pada masyarakat luas.

## Penutup

#### Saat ini model untuk memprediksi diabetes telah didapatkan. Dengan model ini diimplementasi lebih lanjut untuk dijadikan sebuah aplikasi yang siap digunakan. Namun, model ini juga masih dapat dikembangkan dengan mencoba algoritma lain, menambahkan fine-tuning, atau merubah dataset.
"""